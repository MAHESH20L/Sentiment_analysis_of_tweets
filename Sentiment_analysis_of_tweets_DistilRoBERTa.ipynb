{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN6Mfj/YQcMigifmxGYu33X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MAHESH20L/Sentiment_analysis_of_tweets/blob/main/Sentiment_analysis_of_tweets_DistilRoBERTa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLw0Cph8PIzv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "\n",
        "from torch.utils.data import Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"BTC_tweets_daily_example.csv\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "VllUnyIgP4UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(r\"@\\w+\", \"\", text)\n",
        "    text = re.sub(r\"#\\w+\", \"\", text)\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "hugwsGuYQ6gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Tweet\"] = df[\"Tweet\"].astype(str)\n",
        "df[\"Tweet\"] = df[\"Tweet\"].apply(clean_text)\n",
        "\n",
        "# Remove rows without labels\n",
        "df = df.dropna(subset=[\"New_Sentiment_State\"])\n"
      ],
      "metadata": {
        "id": "9i-K7W-8Q--z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_mapping = {\n",
        "    label: idx for idx, label in enumerate(sorted(df[\"New_Sentiment_State\"].unique()))\n",
        "}\n",
        "\n",
        "df[\"label\"] = df[\"New_Sentiment_State\"].map(label_mapping)\n",
        "\n",
        "num_labels = len(label_mapping)\n",
        "print(\"Label mapping:\", label_mapping)\n"
      ],
      "metadata": {
        "id": "CBVMzgikRD4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df[\"Tweet\"],\n",
        "    df[\"label\"],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df[\"label\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "p5wuccXZRHTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"distilroberta-base\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=num_labels\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "gTVwJsmlRPG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TweetDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenizer(\n",
        "            texts.tolist(),\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            max_length=128\n",
        "        )\n",
        "        self.labels = labels.tolist()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n"
      ],
      "metadata": {
        "id": "DsT6wrxoRWbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TweetDataset(X_train, y_train)\n",
        "test_dataset = TweetDataset(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "t7VbmtDeRZuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=1,        # üî• FAST\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=100,\n",
        "    save_strategy=\"no\",\n",
        "    eval_strategy=\"no\",\n",
        "    fp16=True,                 # üî• MUCH FASTER ON GPU\n",
        "    report_to=\"none\"\n",
        ")"
      ],
      "metadata": {
        "id": "2crpxzeKRcuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset\n",
        ")"
      ],
      "metadata": {
        "id": "bB58Hj6lRu9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "Je3EBj2DSUxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trainer.predict(test_dataset)\n",
        "y_pred = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=[str(key) for key in label_mapping.keys()]))"
      ],
      "metadata": {
        "id": "JNm0FzBiSgEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap=\"Blues\")\n",
        "plt.title(\"DistilRoBERTa Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5PZPjZv3SojS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-_3RFu94WYqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert numeric labels to Series\n",
        "actual_counts = pd.Series(y_test).value_counts().sort_index()\n",
        "pred_counts = pd.Series(y_pred).value_counts().sort_index()\n",
        "\n",
        "# Align indexes so missing classes don't cause NaN\n",
        "df_plot = pd.DataFrame({\n",
        "    \"Actual\": actual_counts,\n",
        "    \"Predicted\": pred_counts\n",
        "}).fillna(0)\n",
        "\n",
        "# Plot\n",
        "df_plot.plot(\n",
        "    kind=\"bar\",\n",
        "    figsize=(6,4)\n",
        ")\n",
        "\n",
        "plt.title(\"Actual vs Predicted Sentiment Distribution\")\n",
        "plt.xlabel(\"Sentiment Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "K6L1WCukWltU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "neg_pos = {\n",
        "    \"Negative\": pred_counts.get(0, 0),   # class 0\n",
        "    \"Positive\": pred_counts.get(2, 0)    # class 2\n",
        "}\n",
        "\n",
        "plt.bar(neg_pos.keys(), neg_pos.values())\n",
        "plt.title(\"Negative vs Positive Predictions\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0UzuqHQpWoST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "plt.bar([\"Accuracy\"], [acc])\n",
        "plt.ylim(0, 1)\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FSYjBnVrbW5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Load DistilRoBERTa\n",
        "MODEL_NAME = \"distilroberta-base\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=3\n",
        ")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Input sentence\n",
        "sentence = \"I just love how Bitcoin destroyed my savings today\"\n",
        "\n",
        "# Tokenize\n",
        "inputs = tokenizer(\n",
        "    sentence,\n",
        "    return_tensors=\"pt\",\n",
        "    truncation=True,\n",
        "    padding=True\n",
        ")\n",
        "\n",
        "# Predict\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    probs = torch.softmax(outputs.logits, dim=1)\n",
        "\n",
        "# Labels (model output space: 0,1,2)\n",
        "labels = {\n",
        "    0: \"Negative üò°\",\n",
        "    1: \"Neutral üòê\",\n",
        "    2: \"Positive üòä\"\n",
        "}\n",
        "\n",
        "# Max-probability decision\n",
        "pred_id = torch.argmax(probs).item()\n",
        "\n",
        "# Output\n",
        "print(\"Sentence:\", sentence)\n",
        "print(\"Probabilities:\")\n",
        "print(\"Negative:\", round(probs[0][0].item(), 3))\n",
        "print(\"Neutral :\", round(probs[0][1].item(), 3))\n",
        "print(\"Positive:\", round(probs[0][2].item(), 3))\n",
        "print(\"\\nFinal Prediction (max prob):\", labels[pred_id])\n"
      ],
      "metadata": {
        "id": "cY28NUnwbZW-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}